# 卷积网络的可视化

## Contact me

* Blog -> <https://cugtyt.github.io/blog/index>
* Email -> <cugtyt@qq.com>, <cugtyt@gmail.com>
* GitHub -> [Cugtyt@GitHub](https://github.com/Cugtyt)

---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

课程作业

## 背景

卷积网络可视化是学界研究的热点问题，由于深度卷积网络参数很多，很多结果难以解释，有许多方法尝试对卷积网络进行可视化解释，以便分析网络性能和不足，分析网络分类错误的原因，以及网络特征的提取情况，帮助提高网络的鲁棒性，改善网络性能，ZFNet借助反卷积网络（Deconvnet）的思想对AlexNet进行了分析，发现了AlexNet 本身存在一些问题，例如第一个卷积层对中间频率覆盖不足，第二层出现混叠效应，对卷积层和池化层进行了修改，用 7×7 的卷积核替代 11×11 的卷积核，步长从4减小到2，这些改动提升了网络的性能。



## CAM

CAM 以热力图的形式展示其对特征激活的程度。卷积网络通过多次卷积和池化之后，卷积层包含了丰富的空间和语义信息，后面的全连接层很难可视化直观分析， CAM 采用了 Network in Network 的思路，使用全局均值池化（ Global Average Pooling， GAP）替换掉了全连接层，便可以通过卷积层提取特征图均值。对于修改后的网络，类别分数为：

$$\begin{aligned} S _ { c } & = \sum _ { k } w _ { k } ^ { c } \sum _ { x , y } f _ { k } ( x , y ) \\ & = \sum _ { x , y } \sum _ { k } w _ { k } ^ { c } f _ { k } ( x , y ) \end{aligned}$$

其中$f _ { k } ( x , y )$表示最后一层卷积层上位于 $(x, y)$ 位置的单元$k$的激活，然后定义类别c的激活图$M_c$：

$$M _ { c } ( x , y ) = \sum _ { k } w _ { k } ^ { c } f _ { k } ( x , y )$$

因此$S _ { c } = \sum _ { x , y } M _ { c } ( x , y )$，那么对于空间位置$(x, y)$上的激活重要性就可以用$M_c(x,y)$表示。CAM的最终结果是不同卷积层特征图叠加，最后叠加到原图上。

![cam](R/cnn-vis-cam.png)

## Grad-CAM

CAM 可以得到不错的解释效果，但是它需要修改模型结构，这就极大限制了应用场景，而后出现的 Grad-CAM 解决了这个问题。 Grad-CAM 思路与 CAM 基本一致，主要区别在于求权重的过程， Grad-CAM 使用梯度的全局平均来计算权重：

$$\alpha_k^c = 
\overbrace{\frac{1}{Z} \sum_i \sum_j}^\text{global average pooling}
\underbrace{\frac{\partial y^c}{\partial A_{i,j}^k}}_\text{gradients via backprop}$$

式中 $Z$ 为特征图像素个数， $y^c$ 是类别分数， $A^k_{i,j}$ 表示第$k$个特征图中$(i,j)$位置处的像素值，求得所有特征图得权重后，对其加权求和可以得到最终的特征图:

$$L _ { \mathrm { Grad-CAM } } ^ { c } = \operatorname { ReL } U \left( \sum _ { k } \alpha _ { k } ^ { c } A ^ { k } \right)$$

Grad-CAM 的整体结构如图。

![grad-cam](R/cnn-vis-grad-cam.png)

## Grad-CAM++

虽然Grad-CAM等方法效果不错但是，这些方法有局限性，例如多个同类目标同时出现的定位，即使是单一物体，Grad-CAM也不能定位完全。我们提出了Grad-CAM++，改良了先前的方法，我们的关键贡献在于：

* 我们引入了输出梯度对于特定位置的像素级别加权。这个方法提供了对每个像素在特征图的重要性衡量，更重要的是我们推导了闭式解，同时获得了高阶的精确表达，包括了softmax和指数激活输出。我们的方法需要一次反向回传，因此计算量和先前的基于梯度的方法一致，但是效果更好。
* 先前的几个方法，如反卷积（Deconvolution），导向反向传播（Guided Backpropagation），CAM，Grad-CAM，他们的结果评判都是靠人眼，或其他辅助标准。我们提出了新的方法来衡量可靠性，也就是说这个可视化结果是否与决策相关，我们的方法有很大优势。
* 好的可视化方法应该能够高效提炼模型的知识。这个方面最近一致被忽视，我们用受限的师生设置（teacher-student setting），发现可以通过特定的损失函数来提升学生的性能，这个损失函数受Grad-CAM++生成的解释图启发。我们引入了一个训练方法，发现效果很好。
* 我们也用了人工的方式来评价可视化效果，发现我们的方法的确很好。
* 通过可视化样本和目标估计，我们展示了Grad-CAM++在弱监督目标定位上相比Grad-CAM有提升。
* 最后，我们展示了Grad-CAM++在图像字幕生成，3D动作识别方面的有效性。据我们所知，这是第一次3D-CNN的可视化。

![grad-cam++](R/cnn-vis-grad-cam++.png)