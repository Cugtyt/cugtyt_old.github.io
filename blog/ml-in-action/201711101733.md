# 《Machine Learning In Action》 中Logistic Regression部分代码精简优化 

---
> ## Contact me:
> Blog -> <https://cugtyt.github.io/blog/index>  
> Email -> <cugtyt@qq.com>, <cugtyt@gmail.com>  
> GitHub -> [Cugtyt@GitHub](https://github.com/Cugtyt)

---

> **本系列博客主页及相关见**[**此处**](https://cugtyt.github.io/blog/ml-in-action/index)  
> **此处粘贴的代码来源为**<https://github.com/Jack-Cherish/Machine-Learning>

---


## 1. stocGradAscent1函数，创建词汇表

**原代码：**

``` python
def stocGradAscent1(dataMatrix, classLabels, numIter=150):
    m,n = np.shape(dataMatrix)                                                #返回dataMatrix的大小。m为行数,n为列数。
    weights = np.ones(n)                                                       #参数初始化
    for j in range(numIter):
        dataIndex = list(range(m))
        for i in range(m):
            alpha = 4/(1.0+j+i)+0.01                    #降低alpha的大小，每次减小1/(j+i)。
            randIndex = int(random.uniform(0,len(dataIndex)))                #随机选取样本
            h = sigmoid(sum(dataMatrix[randIndex]*weights))                    #选择随机选取的一个样本，计算h
            error = classLabels[randIndex] - h                                 #计算误差
            weights = weights + alpha * error * dataMatrix[randIndex]       #更新回归系数
            del(dataIndex[randIndex])                                         #删除已经使用的样本
    return weights    #返回
```

问题：  

函数中选择对已使用样本进行删除，但是在实际的测试中并没有发现此操作相比与随机使用样本不删除有明显优化效果，因此可以直接使用随机样本。
同时按照参数初始化的原则，应该使用随机数初始化weights。

**参考修改：**

``` python
def stocGradAscent1(dataMatrix, classLabels, numIter=150):
    m, n = np.shape(dataMatrix)
    weights = np.random.randn(n)                                                
    for j in range(numIter * m):                                           
        alpha = 1 / (1.0 + j) + 0.01       #降低alpha的大小，每次减小1/(j+i)。
        randIndex = random.randint(0, m - 1)                #随机选取样本
        h = sigmoid(sum(dataMatrix[randIndex] * weights))          #选择随机选取的一个样本，计算h
        error = classLabels[randIndex] - h                      #计算误差
        weights = weights + alpha * error * dataMatrix[randIndex]       #更新回归系数
    return weights
```

## 2. 使用列表推导简化代码

**原代码：**

``` python
lineArr =[]
for i in range(len(currLine)-1):
    lineArr.append(float(currLine[i]))
```

问题：  

使用列表推到简洁高效

**参考修改：**

``` python
lineArr = [float(currLine[i]) for i in range(len(currLine) - 1)]
```