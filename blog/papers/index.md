# **Blogs of Papers**

## Contact me

* Blog -> <https://cugtyt.github.io/blog/index>
* Email -> <cugtyt@qq.com>, <cugtyt@gmail.com>
* GitHub -> [Cugtyt@GitHub](https://github.com/Cugtyt)

---

本系列博客主要是关于阅读论文的笔记。

---

## [**[R-CNN] Rich feature hierarchies for accurate object detection and semantic segmentation**](https://cugtyt.github.io/blog/papers/2018/0803)

> 自底向上区域提议+CNN

---

## [**YOLOv3: An Incremental Improvement**](https://cugtyt.github.io/blog/papers/2018/0802)

> 对网络结构做了一些变动

---

## [**YOLO9000: Better, Faster, Stronger**](https://cugtyt.github.io/blog/papers/2018/0731)

> 使用一些方法提升了YOLO的性能，使用聚类设置框维度，使用分类数据和检测数据联合训练

---

## [**You Only Look Once: Unified, Real-Time Object Detection**](https://cugtyt.github.io/blog/papers/2018/0728)

> YOLO只使用一个神经网络，用回归问题解决目标检测，速度快，相比R-CNN准确率还差点

---

## [**Wasserstein GAN**](https://cugtyt.github.io/blog/papers/2018/0727)

> EM与其他距离和散度的比较，WGAN可以提升稳定性，更好的收敛

---

## [**Are GANs Created Equal? A Large-Scale Study**](https://cugtyt.github.io/blog/papers/2018/0725)

> fair and comprehensive comparison of the state-of-the-art GANs, it is necessary to report a summary of distribution of results, a series of tasks of increasing difficulty for which undisputed measures.  
> We find that most models can reach similar scores with enough hyperparameter optimization and random restarts. This suggests that improvements can arise from a higher computational budget and tuning more than fundamental algorithmic changes.

---

## [**The GAN Landscape: Losses, Architectures, Regularization, and Normalization**](https://cugtyt.github.io/blog/papers/2018/0723)

> losses, regularization and normalization schemes, and neural architectures, and their impact on the on the quality of generated samples which we assess by recently introduced quantitative metrics.

---

## [**MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications**](https://cugtyt.github.io/blog/papers/2018/0721)

> Depthwise Separable Convolution, Width Multiplier: Thinner Models, Resolution Multiplier: Reduced Representation

---